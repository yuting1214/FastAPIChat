<p align="center">
  <a href="https://github.com/yuting1214/FastAPIChat">
    <img src="frontend/login/static/favicon.ico" height="50">
  </a>
  <h1 align="center">
    <a href="https://github.com/yuting1214/FastAPIChat">FastAPIChat</a>
  </h1>
</p>

<p align="center">
<a href="https://railway.app/template/_-qAbG?referralCode=jk_FgY">
  <img src="https://railway.app/button.svg" alt="Deploy on Railway" height="30">
</a> 
</p>


FastAPIChat is a powerful application for testing and evaluating large language model based chatbots.
- FastAPIChat powers [LLM Arena](https://gradioapp-production.up.railway.app/arena/), serving over 10+ LLMs, for diverse and dynamic chatbot interactions
- FastAPIChat enables seamlessly rate [LLM](https://gradioapp-production.up.railway.app/chatbot/) generated responses, ensuring continuous improvement based on user feedback.

![Demo of FastAPIChat](https://github.com/yuting1214/FastAPIChat/blob/main/materials/demo.gif)

## News
- [2024/06] ğŸ”¥ We released FastAPIChat v1.0.0

<details>
<summary>More</summary>

- [2024/06] We released FastAPIChat v1.0.0 with ChatBot and ChatBot Arena

</details>

<a href="https://chat.lmsys.org"><img src="assets/demo_narrow.gif" width="70%"></a>

## ğŸ‰ Key Features and Integrations
Key features:

* ğŸ’¬ LLM Chats(10+ LLMs)
* âš”ï¸ LLM Arena
* ğŸ—³ï¸ Chat Feedback collection
* âš¡ FastAPI API Documentation and Authentication

FastAPIChat integrates seamlessly with Python programs and libraries and includes out-of-the-box integrations for:

- [LangChain](https://docs.chainlit.io/integrations/langchain)
- [OpenRouter](https://openrouter.ai/)
- [Gradio](https://www.gradio.app/)

## Quick-Start ğŸš€

Note: To begin, you'll need an API key from [OpenRouter](https://openrouter.ai/keys).

### Development Mode

* Note: In Dev mode, the default config with backend is **SQLite**.

1. Clone Repo:

```
git clone https://github.com/yuting1214/FastAPIChat.git
```

2. Configure Virtual Environment (Recommended):
<details>
  
   * Create Virtual Environment
   
     ```
     # macOS/Linux
     # You may need to run `sudo apt-get install python3-venv` first on Debian-based OSs
     python3 -m venv .venv
     
     # Windows
     # You can also use `py -3 -m venv .venv`
     python -m venv .venv
     ```

   * Activate the virtual environment:
     ```
     # macOS/Linux
     source .venv/bin/activate
     
     # Windows
     .venv\Scripts\activate
     ```
</details>
     
3. Install Dependencies:
```
pip install -r requirements.txt
```

4. Update the .env file with

```
USER_NAME=<API_Doc_Username>
PASSWORD=min=<API_Doc_PASSWORD>
OPENROUTER_API_KEY=<Your_API_KEY>
```

5. Run the application:

```
python -m backend.app.main --mode dev 
```

### Production Mode

1. Add extra envs in with your environment configurations:

```
DB_ENGINE=<Your_DB_config>
DB_USERNAME=<Your_DB_config>
DB_PASS=<Your_DB_config>
DB_HOST=<Your_DB_config>
DB_PORT=<Your_DB_config>
DB_NAME=<Your_DB_config>
API_BASE_URL=<Your_Host_URL>
```

2. Run the application:

```
python -m backend.app.main --mode prod
```

* Alternatively, use Dockerfile for deployment.

## App Settings ğŸ“‹

### Managing Quota

* Control quotas by adjusting limits in `backend/app/core/constants.py`:

```
TEXT_API_QUOTA_LIMIT = <int>
```

### Adding New LLM Models (OpenRouter)

* To add a new LLM model, specify its details in backend/data/llm_models:

```
    {
        'llm_model_name': 'Mixtral 8x22B',
        'llm_vendor': 'Mistral AI',
        'llm_type': 'text',
        'api_provider': 'OpenRouter',
        'api_endpoint': 'mistralai/mixtral-8x22b-instruct',
    }
```

## Features ğŸŒŸ

1. **Utilize Gradio and FastAPI Integration**: Seamlessly combine Gradio for the frontend display and FastAPI for robust backend functionality, offering a smooth user experience.

2. **Well-Crafted API Management**: Our meticulously designed API ensures efficient data transportation and effective management of API quota usage, providing users with a reliable and hassle-free experience.

3. **Integration of Leading Language Models**: Integrate more than 10+ popular language models from various vendors, including OpenAI, Mistral, Meta and Anthropic, enabling users to leverage cutting-edge AI capabilities for text generation.

4. **Comprehensive Testing and Documentation**: Benefit from comprehensive testing suites and detailed documentation, empowering developers to understand and contribute to the project with ease, ensuring robustness and maintainability.
Third-Party Services: Integrate with third-party APIs for enhanced functionality.

5. **Third-Party Services Integration**: Seamlessly integrates with third-party APIs for enhanced functionality.

## Project Structure ğŸ“

* Project Details: [Heptabase](https://app.heptabase.com/w/80fcc9a0476f3a3ac30ac895c36eef51ede0bc4aa090cb7be1c6c0ed507cfda9)

<details>
<summary>More Project Details</summary>

```
FastAPIChat/
â”œâ”€â”€ backend/                      # Backend directory for the FastAPI application
â”‚   â”œâ”€â”€ app/                      # Main application directory
â”‚   â”‚   â”œâ”€â”€ __init__.py           # Initialization file for the app package
â”‚   â”‚   â”œâ”€â”€ api/                  # Directory for API related code
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py       # Initialization file for the API package
â”‚   â”‚   â”‚   â”œâ”€â”€ v1/               # Version 1 of the API
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py   # Initialization file for the v1 API package
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ endpoints/    # Directory for API endpoint definitions
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py          # Initialization file for endpoints package
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ text_generation.py   # Endpoints for text generation
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llm_management.py    # Endpoints for LLM model management
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ api_usage.py         # Endpoints for API usage management
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ api_calldetail.py    # Endpoints for API Detail management
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ message.py           # Endpoints for messasge management
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py              # Endpoints for chat management
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ rating.py            # Endpoints for rating management
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ user.py              # Endpoints for user management
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ quota.py             # Endpoints for quota management
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ doc.py               # Endpoints for OpenAPI doc management
â”‚   â”‚   â”œâ”€â”€ dependencies/         # Directory for dependency management
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py       # Initialization file for dependencies package
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py       # Database connection and session management
â”‚   â”‚   â”‚   â”œâ”€â”€ rate_limiter.py   # Rate limiting logic
â”‚   â”‚   â”œâ”€â”€ core/                 # Core application logic
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py       # Initialization file for core package
â”‚   â”‚   â”‚   â”œâ”€â”€ constant.py       # Constant settings
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py         # Configuration settings
â”‚   â”‚   â”‚   â”œâ”€â”€ init_setting.py   # Init settings with user's input
â”‚   â”‚   â”œâ”€â”€ models/               # Directory for SQLAlchemy models
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py       # Initialization file for models package
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py           # User model
â”‚   â”‚   â”‚   â”œâ”€â”€ quota.py          # Quota model
â”‚   â”‚   â”‚   â”œâ”€â”€ message.py        # Message model
â”‚   â”‚   â”‚   â”œâ”€â”€ api_usage.py      # API usage model
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.py            # LLM model
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py           # Chat model
â”‚   â”‚   â”‚   â”œâ”€â”€ rating.py         # rating model
â”‚   â”‚   â”œâ”€â”€ schemas/              # Directory for Pydantic schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py       # Initialization file for schemas package
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py           # Schemas for user data
â”‚   â”‚   â”‚   â”œâ”€â”€ quota.py          # Schemas for quota data
â”‚   â”‚   â”‚   â”œâ”€â”€ message.py        # Schemas for message data
â”‚   â”‚   â”‚   â”œâ”€â”€ api_usage.py      # Schemas for API usage data
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.py            # Schemas for LLM model data
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_message.py    # Schemas for LLM generated output data
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py           # Schemas for chat data
â”‚   â”‚   â”‚   â”œâ”€â”€ rating.py         # Schemas for rating data
â”‚   â”‚   â”œâ”€â”€ crud/                 # Directory for CRUD operations
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py       # Initialization file for crud package
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py           # CRUD for user management
â”‚   â”‚   â”‚   â”œâ”€â”€ quota.py          # CRUD for quota management
â”‚   â”‚   â”‚   â”œâ”€â”€ message.py        # CRUD for message management
â”‚   â”‚   â”‚   â”œâ”€â”€ api_usage.py      # CRUD for API usage management
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.py            # CRUD for LLM model management
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_message.py    # CRUD for LLM generated output management
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py           # CRUD for chat management
â”‚   â”‚   â”‚   â”œâ”€â”€ rating.py         # CRUD for rating management
â”‚   â”‚   â”œâ”€â”€ main.py               # Main FastAPI application file
â”‚   â”œâ”€â”€ data/                     # Directory for data when initiating db
â”‚   â”‚   â”œâ”€â”€ __init__.py           # Initialization file for data package
â”‚   â”‚   â”œâ”€â”€ llm_models.py         # LLM models infomation
â”‚   â”œâ”€â”€ security/                  # New directory for authentication and authorization
â”‚   â”‚   â”œâ”€â”€ __init__.py            # Initialization file for security package
â”‚   â”‚   â”œâ”€â”€ authentication.py      # Authentication logic
â”‚   â”‚   â”œâ”€â”€ authorization.py       # Authorization logic
â”‚   â”œâ”€â”€ tests/                    # Directory for test files
â”‚   â”‚   â”œâ”€â”€ __init__.py           # Initialization file for tests package
â”‚   â”‚   â”œâ”€â”€ test_text_generation.py  # Tests for text generation endpoints
â”œâ”€â”€ frontend/                     # Frontend directory for the Gradio app
â”‚   â”œâ”€â”€ __init__.py               # Initialization file for frontend package
â”‚   â”œâ”€â”€ gradio/                   # Main gradio UI directory
â”‚   â”‚   â”œâ”€â”€ __init__.py           # Initialization file for the gradio package
â”‚   â”‚   â”œâ”€â”€ text/                 # Directory for ChatBot UI related code
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py       # Initialization file for the text package
â”‚   â”‚   â”‚   â”œâ”€â”€ event_listeners.py #      
â”‚   â”‚   â”‚   â”œâ”€â”€ text_generation.py # 
â”‚   â”‚   â”‚   â”œâ”€â”€ text_generation_arena.py               
â”‚   â”œâ”€â”€ login/                     # Main login UI directory
â”‚   â”‚   â”œâ”€â”€ __init__.py           # Initialization file for the gradio package
â”‚   â”‚   â”œâ”€â”€ static/               # Directory for static files
â”‚   â”‚   â”‚   â”œâ”€â”€ style.css         # CSS for login UI               
â”‚   â”‚   â”œâ”€â”€ templates/            # Directory for HTML templates
â”‚   â”‚   â”‚   â”œâ”€â”€ base.html         # HTML base template
â”‚   â”‚   â”‚   â”œâ”€â”€ login.html        # HTML login template   
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ __init__.py               # Makes llm a Python package
â”‚   â”œâ”€â”€ llm_text_chain.py         # Module for LLM text generation integration
â”‚   â””â”€â”€ prompt/                   # Folder for prompt handling
â”‚       â”œâ”€â”€ __init__.py           # Initializes the prompt package
â”‚       â”œâ”€â”€ base_text_templates.py# Stores base prompt templates for text generation
â”‚       â””â”€â”€ examples/             # Directory for few-shot examples used by the chain
â”‚       â””â”€â”€ deprecated/           # Directory for deprecated prompts
â”‚   â””â”€â”€ vendors/                  # Directory for vendor-specific LLM configurations
â”‚       â”œâ”€â”€ __init__.py           # Makes vendors a Python package
â”‚       â””â”€â”€ openrouter.py         # Configurations and usage for OpenRouter as LLM provider
â”œâ”€â”€ .env                          # Environment variables file
â”œâ”€â”€ .gitignore                    # Git ignore file
â”œâ”€â”€ requirements.txt              # Python dependencies file
â”œâ”€â”€ Dockerfile                    # Docker configuration
â”œâ”€â”€ README.md                     # Project README file
```
</details>

## Future Direction ğŸ“

1. Integraion of local LLM: Integrate with [Ollama](https://github.com/ollama/ollama) to enable users to run LLMs locally and battle with LLMs from API.

2. Integraion of RAG LLM: Enable users to compare different configuration of RAG LLM in LLM Arena.

3. Integration of Redis or other NoSQL Databases: Incorporate Redis or other NoSQL databases to efficiently track and store user history data, enabling personalized experiences and insights for users.

4. History Message Management: Allow user to fetch back the previous messages from database and continue the chat.

5. Rate Limiter: Integrate rate limiter for API protection.

## Contributing ğŸ¤
We welcome contributions from the community! Whether it's bug fixes, feature enhancements, or documentation improvements, feel free to open a pull request.

---

Designed with :heart: by [Mark Chen](https://github.com/yuting1214)
